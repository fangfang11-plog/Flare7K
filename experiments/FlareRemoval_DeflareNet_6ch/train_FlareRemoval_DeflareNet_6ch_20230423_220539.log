2023-04-23 22:05:39,692 INFO: 
                ____                _       _____  ____
               / __ ) ____ _ _____ (_)_____/ ___/ / __ \
              / __  |/ __ `// ___// // ___/\__ \ / /_/ /
             / /_/ // /_/ /(__  )/ // /__ ___/ // _, _/
            /_____/ \__,_//____//_/ \___//____//_/ |_|
     ______                   __   __                 __      __
    / ____/____   ____   ____/ /  / /   __  __ _____ / /__   / /
   / / __ / __ \ / __ \ / __  /  / /   / / / // ___// //_/  / /
  / /_/ // /_/ // /_/ // /_/ /  / /___/ /_/ // /__ / /<    /_/
  \____/ \____/ \____/ \____/  /_____/\____/ \___//_/|_|  (_)
    
Version Information: 
	BasicSR: 1.4.1
	PyTorch: 1.9.0+cu111
	TorchVision: 0.10.0+cu111
2023-04-23 22:05:39,692 INFO: 
  name: FlareRemoval_DeflareNet_6ch
  model_type: DDeflareModel
  scale: 1
  num_gpu: 1
  manual_seed: 0
  datasets:[
    train:[
      name: Flare7K
      type: Flare_Pair_Loader
      image_path: ../dataset/Flickr24K
      scattering_dict:[
        Flare7K_scattering: ../dataset/Flare7k/Scattering_Flare/Glare_with_shimmer
      ]
      reflective_dict:[
        Flare7K_reflective: ../dataset/Flare7k/Reflective_Flare
      ]
      transform_base:[
        img_size: 512
      ]
      transform_flare:[
        scale_min: 0.8
        scale_max: 1.5
        translate: 300
        shear: 20
      ]
      mask_type: None
      use_shuffle: True
      num_worker_per_gpu: 0
      batch_size_per_gpu: 1
      dataset_enlarge_ratio: 1
      prefetch_mode: None
      phase: train
      scale: 1
    ]
    val:[
      name: flare_test
      type: Image_Pair_Loader
      dataroot_gt: ../dataset/Flare7k/test_data/real/gt
      dataroot_lq: ../dataset/Flare7k/test_data/real/input
      gt_size: 512
      phase: val
      scale: 1
    ]
  ]
  network_g:[
    type: DeflareNet
    img_size: 512
    img_ch: 3
    output_ch: 3
    use_se: True
  ]
  path:[
    pretrain_network_g: None
    strict_load_g: True
    resume_state: None
    experiments_root: D:\data\tunnel\Flare\experiments\FlareRemoval_DeflareNet_6ch
    models: D:\data\tunnel\Flare\experiments\FlareRemoval_DeflareNet_6ch\models
    training_states: D:\data\tunnel\Flare\experiments\FlareRemoval_DeflareNet_6ch\training_states
    log: D:\data\tunnel\Flare\experiments\FlareRemoval_DeflareNet_6ch
    visualization: D:\data\tunnel\Flare\experiments\FlareRemoval_DeflareNet_6ch\visualization
  ]
  train:[
    optim_g:[
      type: Adam
      lr: 0.0001
      weight_decay: 0
      betas: [0.9, 0.99]
    ]
    scheduler:[
      type: MultiStepLR
      milestones: [200000]
      gamma: 1.0
    ]
    ema_decay: 0
    total_iter: 1200000
    warmup_iter: -1
    l1_opt:[
      type: L_Abs_pure
      loss_weight: 0.5
    ]
    perceptual:[
      type: L_percepture
      loss_weight: 0.5
    ]
  ]
  val:[
    val_freq: 5000.0
    save_img: True
    metrics:[
      psnr:[
        type: calculate_psnr
        crop_border: 4
        test_y_channel: False
      ]
      ssim:[
        type: calculate_ssim
        crop_border: 4
        test_y_channel: False
      ]
    ]
  ]
  logger:[
    print_freq: 100
    save_checkpoint_freq: 50000.0
    use_tb_logger: True
    wandb:[
      project: None
      resume_id: None
    ]
  ]
  dist_params:[
    backend: nccl
    port: 29500
  ]
  dist: False
  rank: 0
  world_size: 1
  auto_resume: False
  is_train: True
  root_path: D:\data\tunnel\Flare

2023-04-23 22:05:40,498 INFO: Dataset [Flare_Pair_Loader] - Flare7K is built.
2023-04-23 22:05:40,499 INFO: Training statistics:
	Number of train images: 23949
	Dataset enlarge ratio: 1
	Batch size per gpu: 1
	World size (gpu number): 1
	Require iter number per epoch: 23949
	Total epochs: 51; iters: 1200000.
2023-04-23 22:05:40,510 INFO: Dataset [Image_Pair_Loader] - flare_test is built.
2023-04-23 22:05:40,511 INFO: Number of val images/folders in flare_test: 100
2023-04-23 22:05:40,520 INFO: Network [DeflareNet] is created.
2023-04-23 22:05:41,587 INFO: Network: DeflareNet, with parameters: 632,746
2023-04-23 22:05:41,587 INFO: DeflareNet(
  (diff_conv): ExpansionConvNet(
    (conv11): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu11): ReLU()
    (conv12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu12): ReLU()
    (conv21): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu21): ReLU()
    (conv22): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
    (relu22): ReLU()
    (conv31): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
    (relu31): ReLU()
    (conv32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))
    (relu32): ReLU()
    (conv_connect): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))
    (conv_optimize): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (no_linear): Sigmoid()
  )
  (resnet18): ResNet18(
    (conv1): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (layer1): Sequential(
      (0): ResBlock(
        (left): Sequential(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (shortcut): Sequential()
      )
      (1): ResBlock(
        (left): Sequential(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (shortcut): Sequential()
      )
    )
    (layer2): Sequential(
      (0): ResBlock(
        (left): Sequential(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (shortcut): Sequential()
      )
      (1): ResBlock(
        (left): Sequential(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (shortcut): Sequential()
      )
    )
    (layer3): Sequential(
      (0): ResBlock(
        (left): Sequential(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (shortcut): Sequential()
      )
      (1): ResBlock(
        (left): Sequential(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (shortcut): Sequential()
      )
    )
    (layer4): Sequential(
      (0): ResBlock(
        (left): Sequential(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (shortcut): Sequential()
      )
      (1): ResBlock(
        (left): Sequential(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (shortcut): Sequential()
      )
    )
    (conv2): Sequential(
      (0): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
  )
)
2023-04-23 22:05:41,588 INFO: Loss [L_Abs_pure] is created.
2023-04-23 22:05:42,392 INFO: Loss [L_percepture] is created.
2023-04-23 22:05:42,393 INFO: Model [DDeflareModel] is created.
2023-04-23 22:05:42,394 INFO: Start training from epoch: 0, iter: 0
2023-04-23 22:07:16,247 INFO: [Flare..][epoch:  0, iter:     100, lr:(1.000e-04,)] [eta: 12 days, 7:36:35, time (data): 0.938 (0.308)] l1_recons: 1.1257e-01 l1_flare: 0.0000e+00 l1_base: 6.6831e-02 l1: 1.7940e-01 l_vgg: 5.5215e+00 l_vgg_base: 5.5215e+00 l_vgg_flare: 0.0000e+00 
2023-04-23 22:08:47,027 INFO: [Flare..][epoch:  0, iter:     200, lr:(1.000e-04,)] [eta: 12 days, 11:03:01, time (data): 0.923 (0.308)] l1_recons: 1.2957e-01 l1_flare: 0.0000e+00 l1_base: 3.7367e-02 l1: 1.6693e-01 l_vgg: 3.3596e+00 l_vgg_base: 3.3596e+00 l_vgg_flare: 0.0000e+00 
2023-04-23 22:10:23,470 INFO: [Flare..][epoch:  0, iter:     300, lr:(1.000e-04,)] [eta: 12 days, 18:27:28, time (data): 0.965 (0.340)] l1_recons: 1.9259e-02 l1_flare: 0.0000e+00 l1_base: 1.2320e-02 l1: 3.1580e-02 l_vgg: 1.1704e+00 l_vgg_base: 1.1704e+00 l_vgg_flare: 0.0000e+00 
2023-04-23 22:11:59,418 INFO: [Flare..][epoch:  0, iter:     400, lr:(1.000e-04,)] [eta: 12 days, 21:44:45, time (data): 0.962 (0.333)] l1_recons: 1.6163e-02 l1_flare: 0.0000e+00 l1_base: 1.3275e-02 l1: 2.9438e-02 l_vgg: 6.1588e-01 l_vgg_base: 6.1588e-01 l_vgg_flare: 0.0000e+00 
2023-04-23 22:13:36,731 INFO: [Flare..][epoch:  0, iter:     500, lr:(1.000e-04,)] [eta: 13 days, 0:37:03, time (data): 0.973 (0.335)] l1_recons: 1.8281e-02 l1_flare: 0.0000e+00 l1_base: 9.6609e-03 l1: 2.7942e-02 l_vgg: 5.2778e-01 l_vgg_base: 5.2778e-01 l_vgg_flare: 0.0000e+00 
2023-04-23 22:15:14,077 INFO: [Flare..][epoch:  0, iter:     600, lr:(1.000e-04,)] [eta: 13 days, 2:32:38, time (data): 0.973 (0.336)] l1_recons: 1.3952e-02 l1_flare: 0.0000e+00 l1_base: 1.7700e-02 l1: 3.1651e-02 l_vgg: 6.5269e-01 l_vgg_base: 6.5269e-01 l_vgg_flare: 0.0000e+00 
2023-04-23 22:16:53,136 INFO: [Flare..][epoch:  0, iter:     700, lr:(1.000e-04,)] [eta: 13 days, 4:43:37, time (data): 0.990 (0.346)] l1_recons: 6.8338e-02 l1_flare: 0.0000e+00 l1_base: 4.6727e-02 l1: 1.1507e-01 l_vgg: 4.4746e+00 l_vgg_base: 4.4746e+00 l_vgg_flare: 0.0000e+00 
2023-04-23 22:18:30,548 INFO: [Flare..][epoch:  0, iter:     800, lr:(1.000e-04,)] [eta: 13 days, 5:40:22, time (data): 0.982 (0.345)] l1_recons: 8.6168e-03 l1_flare: 0.0000e+00 l1_base: 1.0207e-02 l1: 1.8824e-02 l_vgg: 4.4706e-01 l_vgg_base: 4.4706e-01 l_vgg_flare: 0.0000e+00 
2023-04-23 22:20:08,214 INFO: [Flare..][epoch:  0, iter:     900, lr:(1.000e-04,)] [eta: 13 days, 6:29:49, time (data): 0.975 (0.342)] l1_recons: 4.4130e-03 l1_flare: 0.0000e+00 l1_base: 2.5688e-02 l1: 3.0101e-02 l_vgg: 1.1610e+00 l_vgg_base: 1.1610e+00 l_vgg_flare: 0.0000e+00 
2023-04-23 22:21:45,007 INFO: [Flare..][epoch:  0, iter:   1,000, lr:(1.000e-04,)] [eta: 13 days, 6:51:38, time (data): 0.971 (0.339)] l1_recons: 3.4857e-03 l1_flare: 0.0000e+00 l1_base: 2.6944e-02 l1: 3.0430e-02 l_vgg: 1.7030e+00 l_vgg_base: 1.7030e+00 l_vgg_flare: 0.0000e+00 
2023-04-23 22:23:21,676 INFO: [Flare..][epoch:  0, iter:   1,100, lr:(1.000e-04,)] [eta: 13 days, 7:06:55, time (data): 0.966 (0.328)] l1_recons: 5.9309e-02 l1_flare: 0.0000e+00 l1_base: 3.2266e-02 l1: 9.1575e-02 l_vgg: 3.2485e+00 l_vgg_base: 3.2485e+00 l_vgg_flare: 0.0000e+00 
2023-04-23 22:24:57,174 INFO: [Flare..][epoch:  0, iter:   1,200, lr:(1.000e-04,)] [eta: 13 days, 6:59:56, time (data): 0.961 (0.326)] l1_recons: 1.8286e-01 l1_flare: 0.0000e+00 l1_base: 9.3222e-02 l1: 2.7608e-01 l_vgg: 8.1053e+00 l_vgg_base: 8.1053e+00 l_vgg_flare: 0.0000e+00 
2023-04-23 22:26:30,752 INFO: [Flare..][epoch:  0, iter:   1,300, lr:(1.000e-04,)] [eta: 13 days, 6:24:17, time (data): 0.936 (0.316)] l1_recons: 6.7931e-02 l1_flare: 0.0000e+00 l1_base: 3.6829e-02 l1: 1.0476e-01 l_vgg: 4.3903e+00 l_vgg_base: 4.3903e+00 l_vgg_flare: 0.0000e+00 
2023-04-23 22:28:05,006 INFO: [Flare..][epoch:  0, iter:   1,400, lr:(1.000e-04,)] [eta: 13 days, 6:03:08, time (data): 0.939 (0.318)] l1_recons: 2.5357e-01 l1_flare: 0.0000e+00 l1_base: 1.3707e-01 l1: 3.9063e-01 l_vgg: 7.8272e+00 l_vgg_base: 7.8272e+00 l_vgg_flare: 0.0000e+00 
2023-04-23 22:29:39,240 INFO: [Flare..][epoch:  0, iter:   1,500, lr:(1.000e-04,)] [eta: 13 days, 5:44:20, time (data): 0.943 (0.320)] l1_recons: 3.4826e-04 l1_flare: 0.0000e+00 l1_base: 2.6579e-03 l1: 3.0061e-03 l_vgg: 4.2223e-01 l_vgg_base: 4.2223e-01 l_vgg_flare: 0.0000e+00 
2023-04-23 22:31:12,992 INFO: [Flare..][epoch:  0, iter:   1,600, lr:(1.000e-04,)] [eta: 13 days, 5:21:40, time (data): 0.940 (0.320)] l1_recons: 6.1337e-04 l1_flare: 0.0000e+00 l1_base: 1.9593e-02 l1: 2.0207e-02 l_vgg: 8.9301e-01 l_vgg_base: 8.9301e-01 l_vgg_flare: 0.0000e+00 
2023-04-23 22:32:45,750 INFO: [Flare..][epoch:  0, iter:   1,700, lr:(1.000e-04,)] [eta: 13 days, 4:49:49, time (data): 0.927 (0.316)] l1_recons: 3.4272e-02 l1_flare: 0.0000e+00 l1_base: 3.2360e-02 l1: 6.6632e-02 l_vgg: 1.8458e+00 l_vgg_base: 1.8458e+00 l_vgg_flare: 0.0000e+00 
2023-04-23 22:34:19,674 INFO: [Flare..][epoch:  0, iter:   1,800, lr:(1.000e-04,)] [eta: 13 days, 4:34:16, time (data): 0.933 (0.322)] l1_recons: 2.5805e-04 l1_flare: 0.0000e+00 l1_base: 2.4830e-03 l1: 2.7410e-03 l_vgg: 3.9993e-01 l_vgg_base: 3.9993e-01 l_vgg_flare: 0.0000e+00 
2023-04-23 22:35:53,233 INFO: [Flare..][epoch:  0, iter:   1,900, lr:(1.000e-04,)] [eta: 13 days, 4:16:21, time (data): 0.937 (0.327)] l1_recons: 3.1463e-01 l1_flare: 0.0000e+00 l1_base: 1.6065e-01 l1: 4.7528e-01 l_vgg: 1.0940e+01 l_vgg_base: 1.0940e+01 l_vgg_flare: 0.0000e+00 
2023-04-23 22:37:26,019 INFO: [Flare..][epoch:  0, iter:   2,000, lr:(1.000e-04,)] [eta: 13 days, 3:52:21, time (data): 0.932 (0.323)] l1_recons: 1.1775e-01 l1_flare: 0.0000e+00 l1_base: 7.2437e-02 l1: 1.9018e-01 l_vgg: 6.3245e+00 l_vgg_base: 6.3245e+00 l_vgg_flare: 0.0000e+00 
2023-04-23 22:38:58,552 INFO: [Flare..][epoch:  0, iter:   2,100, lr:(1.000e-04,)] [eta: 13 days, 3:28:05, time (data): 0.924 (0.315)] l1_recons: 9.7593e-05 l1_flare: 0.0000e+00 l1_base: 2.6846e-03 l1: 2.7822e-03 l_vgg: 2.5042e-01 l_vgg_base: 2.5042e-01 l_vgg_flare: 0.0000e+00 
2023-04-23 22:40:31,628 INFO: [Flare..][epoch:  0, iter:   2,200, lr:(1.000e-04,)] [eta: 13 days, 3:10:48, time (data): 0.927 (0.317)] l1_recons: 8.6833e-03 l1_flare: 0.0000e+00 l1_base: 2.7290e-02 l1: 3.5973e-02 l_vgg: 1.0539e+00 l_vgg_base: 1.0539e+00 l_vgg_flare: 0.0000e+00 
2023-04-23 22:42:03,523 INFO: [Flare..][epoch:  0, iter:   2,300, lr:(1.000e-04,)] [eta: 13 days, 2:44:39, time (data): 0.920 (0.316)] l1_recons: 2.8567e-01 l1_flare: 0.0000e+00 l1_base: 1.5275e-01 l1: 4.3841e-01 l_vgg: 1.0494e+01 l_vgg_base: 1.0494e+01 l_vgg_flare: 0.0000e+00 
2023-04-23 22:43:36,857 INFO: [Flare..][epoch:  0, iter:   2,400, lr:(1.000e-04,)] [eta: 13 days, 2:32:31, time (data): 0.927 (0.322)] l1_recons: 1.3540e-07 l1_flare: 0.0000e+00 l1_base: 1.5713e-03 l1: 1.5714e-03 l_vgg: 5.2787e-02 l_vgg_base: 5.2787e-02 l_vgg_flare: 0.0000e+00 
2023-04-23 22:45:08,803 INFO: [Flare..][epoch:  0, iter:   2,500, lr:(1.000e-04,)] [eta: 13 days, 2:10:08, time (data): 0.920 (0.316)] l1_recons: 2.0027e-06 l1_flare: 0.0000e+00 l1_base: 6.4343e-03 l1: 6.4363e-03 l_vgg: 2.2741e-01 l_vgg_base: 2.2741e-01 l_vgg_flare: 0.0000e+00 
2023-04-23 22:46:41,077 INFO: [Flare..][epoch:  0, iter:   2,600, lr:(1.000e-04,)] [eta: 13 days, 1:51:53, time (data): 0.922 (0.316)] l1_recons: 2.3196e-08 l1_flare: 0.0000e+00 l1_base: 4.4404e-03 l1: 4.4404e-03 l_vgg: 8.5297e-02 l_vgg_base: 8.5297e-02 l_vgg_flare: 0.0000e+00 
2023-04-23 22:48:13,880 INFO: [Flare..][epoch:  0, iter:   2,700, lr:(1.000e-04,)] [eta: 13 days, 1:38:47, time (data): 0.930 (0.320)] l1_recons: 2.4666e-01 l1_flare: 0.0000e+00 l1_base: 1.3365e-01 l1: 3.8031e-01 l_vgg: 8.9873e+00 l_vgg_base: 8.9873e+00 l_vgg_flare: 0.0000e+00 
2023-04-23 22:49:46,223 INFO: [Flare..][epoch:  0, iter:   2,800, lr:(1.000e-04,)] [eta: 13 days, 1:23:13, time (data): 0.926 (0.319)] l1_recons: 1.6668e-08 l1_flare: 0.0000e+00 l1_base: 3.1082e-02 l1: 3.1082e-02 l_vgg: 8.2042e-01 l_vgg_base: 8.2042e-01 l_vgg_flare: 0.0000e+00 
2023-04-23 22:51:18,854 INFO: [Flare..][epoch:  0, iter:   2,900, lr:(1.000e-04,)] [eta: 13 days, 1:10:37, time (data): 0.928 (0.318)] l1_recons: 7.0213e-06 l1_flare: 0.0000e+00 l1_base: 1.1500e-03 l1: 1.1571e-03 l_vgg: 9.0827e-02 l_vgg_base: 9.0827e-02 l_vgg_flare: 0.0000e+00 
2023-04-23 22:52:52,242 INFO: [Flare..][epoch:  0, iter:   3,000, lr:(1.000e-04,)] [eta: 13 days, 1:03:46, time (data): 0.931 (0.321)] l1_recons: 1.6514e-08 l1_flare: 0.0000e+00 l1_base: 4.3058e-02 l1: 4.3058e-02 l_vgg: 6.7567e-01 l_vgg_base: 6.7567e-01 l_vgg_flare: 0.0000e+00 
2023-04-23 22:54:26,580 INFO: [Flare..][epoch:  0, iter:   3,100, lr:(1.000e-04,)] [eta: 13 days, 1:03:23, time (data): 0.944 (0.328)] l1_recons: 2.5317e-06 l1_flare: 0.0000e+00 l1_base: 7.4189e-03 l1: 7.4215e-03 l_vgg: 2.6600e-01 l_vgg_base: 2.6600e-01 l_vgg_flare: 0.0000e+00 
2023-04-23 23:08:31,786 INFO: [Flare..][epoch:  0, iter:   3,200, lr:(1.000e-04,)] [eta: 16 days, 7:01:52, time (data): 0.951 (0.330)] l1_recons: 6.9481e-02 l1_flare: 0.0000e+00 l1_base: 6.5625e-02 l1: 1.3511e-01 l_vgg: 3.6259e+00 l_vgg_base: 3.6259e+00 l_vgg_flare: 0.0000e+00 
